{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[2.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [2.]]), tensor([[3.],\n",
      "        [3.],\n",
      "        [3.],\n",
      "        [3.],\n",
      "        [3.]]), tensor([[4.],\n",
      "        [4.],\n",
      "        [4.],\n",
      "        [4.]]), tensor([[5.],\n",
      "        [5.],\n",
      "        [5.]]), tensor([[6.],\n",
      "        [6.]]), tensor([[7.]])]\n",
      "tensor([[[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[2.],\n",
      "         [2.],\n",
      "         [2.],\n",
      "         [2.],\n",
      "         [2.],\n",
      "         [2.],\n",
      "         [0.]],\n",
      "\n",
      "        [[3.],\n",
      "         [3.],\n",
      "         [3.],\n",
      "         [3.],\n",
      "         [3.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[4.],\n",
      "         [4.],\n",
      "         [4.],\n",
      "         [4.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[5.],\n",
      "         [5.],\n",
      "         [5.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[6.],\n",
      "         [6.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[7.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]])\n",
      "tensor([[[5.],\n",
      "         [5.],\n",
      "         [5.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[7.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]])\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "#https://zhuanlan.zhihu.com/p/59772104\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as data\n",
    "\n",
    "train_x = [torch.Tensor([[1], [1], [1], [1], [1], [1], [1]]),\n",
    "           torch.Tensor([[2], [2], [2], [2], [2], [2]]),\n",
    "           torch.Tensor([[3], [3], [3], [3], [3]]),\n",
    "           torch.Tensor([[4], [4], [4], [4]]),\n",
    "           torch.Tensor([[5], [5], [5]]),\n",
    "           torch.Tensor([[6], [6]]),\n",
    "           torch.Tensor([[7]])\n",
    "           ]\n",
    "pad_x = rnn_utils.pad_sequence(train_x, batch_first=True)\n",
    "print(train_x)\n",
    "print(pad_x)\n",
    "class MyData(data.Dataset):\n",
    "    def __init__(self, data_seq):\n",
    "        self.data_seq = data_seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_seq[idx]\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    #data = MyData(train_x)\n",
    "    data = MyData(pad_x)\n",
    "    data_loader = DataLoader(data, batch_size=2, shuffle=True)\n",
    "    batch_x = iter(data_loader).next()\n",
    "    print(batch_x)\n",
    "    print('END')\n",
    "    #以数据的最大长度，后两位都是00，在lstm中浪费两次计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[5.],\n",
      "         [5.],\n",
      "         [5.]],\n",
      "\n",
      "        [[6.],\n",
      "         [6.],\n",
      "         [0.]]])\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "#pad\n",
    "def collate_fn(data):\n",
    "    data.sort(key=lambda x: len(x), reverse=True)\n",
    "    data = rnn_utils.pad_sequence(data, batch_first=True, padding_value=0)\n",
    "    return data\n",
    "\n",
    "if __name__=='__main__':\n",
    "    data = MyData(train_x)\n",
    "    data_loader = DataLoader(data, batch_size=2, shuffle=True, \n",
    "                             collate_fn=collate_fn)\n",
    "    batch_x = iter(data_loader).next()\n",
    "    print(batch_x)\n",
    "    print('END')\n",
    "    #以batch的最大长度为准，而不是整个数据的最大长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[3.],\n",
      "         [3.],\n",
      "         [3.],\n",
      "         [3.],\n",
      "         [3.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[4.],\n",
      "         [4.],\n",
      "         [4.],\n",
      "         [4.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]]) [7, 5, 4]\n",
      "PackedSequence(data=tensor([[1.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [1.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [1.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [1.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [1.],\n",
      "        [3.],\n",
      "        [1.],\n",
      "        [1.]]), batch_sizes=tensor([3, 3, 3, 3, 2, 1, 1]))\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(data):\n",
    "    data.sort(key=lambda x: len(x), reverse=True)\n",
    "    data_length = [len(sq) for sq in data]\n",
    "    data = rnn_utils.pad_sequence(data, batch_first=True, padding_value=0)\n",
    "    return data, data_length\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    data = MyData(train_x)\n",
    "    data_loader = DataLoader(data, batch_size=3, shuffle=True, \n",
    "                             collate_fn=collate_fn)\n",
    "    batch_x, batch_x_len = iter(data_loader).next()\n",
    "    batch_x_pack = rnn_utils.pack_padded_sequence(batch_x, \n",
    "                                                  batch_x_len, batch_first=True)\n",
    "print(batch_x,batch_x_len)\n",
    "print(batch_x_pack)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [1.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [1.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [1.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [1.],\n",
      "        [3.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "tensor([[-0.6299],\n",
      "        [-2.4603],\n",
      "        [-3.3756],\n",
      "        [-0.6299],\n",
      "        [-2.4603],\n",
      "        [-3.3756],\n",
      "        [-0.6299],\n",
      "        [-2.4603],\n",
      "        [-3.3756],\n",
      "        [-0.6299],\n",
      "        [-2.4603],\n",
      "        [-3.3756],\n",
      "        [-0.6299],\n",
      "        [-2.4603],\n",
      "        [-0.6299],\n",
      "        [-0.6299]], grad_fn=<AddmmBackward>)\n",
      "tensor([3, 3, 3, 3, 2, 1, 1])\n",
      "[tensor([[-0.6299, -2.4603, -3.3756]]), tensor([[-0.6299, -2.4603, -3.3756]])]\n"
     ]
    }
   ],
   "source": [
    "x=batch_x_pack.data.reshape(-1,1)#the size -1 is inferred from other dimensions\n",
    "print(x)\n",
    "Linear=nn.Linear(1,1)#(input_dim,out_dim)\n",
    "print(Linear(x))\n",
    "#再将linear输出变回为pack 数据\n",
    "len_s=batch_x_pack. batch_sizes\n",
    "print(len_s)\n",
    "h=[]\n",
    "h.append(Linear(x).data[0:len_s[1]].reshape(1,-1))\n",
    "h.append(Linear(x).data[(len_s[1]):(len_s[1]+len_s[2])].reshape(1,-1))\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedSequence(data=tensor([[3.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [3.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [3.],\n",
      "        [5.],\n",
      "        [3.],\n",
      "        [3.]]), batch_sizes=tensor([3, 3, 2, 1, 1]))\n",
      "torch.Size([10, 10])\n",
      "torch.Size([10, 1])\n",
      "tensor([3, 3, 2, 1, 1])\n",
      "tensor([3, 3, 2, 1, 1])\n",
      "PackedSequence(data=tensor([[ 0.7237, -0.7593,  0.4972,  0.3638,  0.0025,  0.1512, -0.3002, -0.1776,\n",
      "          0.5667,  0.4305],\n",
      "        [ 0.4755, -0.8211,  0.6660,  0.3290,  0.1670,  0.4700, -0.3020, -0.1033,\n",
      "          0.6025,  0.6784],\n",
      "        [ 0.5471, -0.8599,  0.6810,  0.1934,  0.4809,  0.3222, -0.7129, -0.0470,\n",
      "          0.3924,  0.8368],\n",
      "        [ 0.6286, -0.7171,  0.5843, -0.2735, -0.1872, -0.3548, -0.7369, -0.1785,\n",
      "         -0.3591,  0.4875],\n",
      "        [ 0.8204, -0.8250,  0.5631, -0.2583,  0.1999, -0.3318, -0.8290,  0.1107,\n",
      "         -0.3554,  0.5253],\n",
      "        [ 0.8422, -0.8556,  0.6322, -0.4389,  0.2007, -0.4008, -0.8284,  0.1744,\n",
      "         -0.4705,  0.4718],\n",
      "        [ 0.6102, -0.6494,  0.7335, -0.4402, -0.4103, -0.4138, -0.7741, -0.1238,\n",
      "         -0.6282,  0.3939],\n",
      "        [ 0.7129, -0.8382,  0.7001, -0.5554, -0.2586, -0.5180, -0.8401,  0.1113,\n",
      "         -0.6403,  0.3623],\n",
      "        [ 0.5875, -0.6347,  0.7273, -0.4332, -0.3953, -0.4271, -0.8231, -0.1360,\n",
      "         -0.7069,  0.4400],\n",
      "        [ 0.5926, -0.6380,  0.7466, -0.4562, -0.3916, -0.4060, -0.8195, -0.1331,\n",
      "         -0.7188,  0.4221]], grad_fn=<CatBackward>), batch_sizes=tensor([3, 3, 2, 1, 1]))\n",
      "torch.Size([2, 3, 10])\n",
      "torch.Size([3, 5, 10])\n",
      "tensor([5, 3, 2])\n",
      "tensor([[ 0.4755, -0.8211,  0.6660,  0.3290,  0.1670,  0.4700, -0.3020, -0.1033,\n",
      "          0.6025,  0.6784],\n",
      "        [ 0.8204, -0.8250,  0.5631, -0.2583,  0.1999, -0.3318, -0.8290,  0.1107,\n",
      "         -0.3554,  0.5253],\n",
      "        [ 0.7129, -0.8382,  0.7001, -0.5554, -0.2586, -0.5180, -0.8401,  0.1113,\n",
      "         -0.6403,  0.3623],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000]], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    data = MyData(train_x)\n",
    "    data_loader = DataLoader(data, batch_size=3, shuffle=True,\n",
    "                             collate_fn=collate_fn)\n",
    "    batch_x, batch_x_len = iter(data_loader).next()\n",
    "    batch_x_pack = rnn_utils.pack_padded_sequence(batch_x, batch_x_len, batch_first=True)\n",
    "\n",
    "    net = nn.RNN(1, 10, 2,batch_first=True)\n",
    "\n",
    "    print(batch_x_pack)\n",
    "    h0 = torch.rand(2, 3, 10)\n",
    "    out, (h1) = net(batch_x_pack,h0)\n",
    "    print(out.data.shape)#第一位表示统计整个数据中共有多少个个非零的数据。即每个数据的RNN的输出。\n",
    "    print(batch_x_pack.data.shape)\n",
    "    print(out.batch_sizes)\n",
    "    print(batch_x_pack.batch_sizes)\n",
    "    print(out)\n",
    "    print(h1.shape)#与h0的shape相同。\n",
    "    out_pad, out_len = rnn_utils.pad_packed_sequence(out, batch_first=True)\n",
    "    print(out_pad.shape)#第一位是句子数，第二位是时间步长（最长的句长），第三维是特征向量维度。\n",
    "    print(out_len)#每一个句子的长度\n",
    "    print(out_pad[1])#假如下标为1的句子真实长度为2，其余位（假如长度位3），共5位，那么out_pad[1]只有前两行有值，其余行为0（3行），\n",
    "    #表示每一个特征映射为hidden_size，其余pad0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[2.],\n",
      "         [2.],\n",
      "         [2.],\n",
      "         [2.],\n",
      "         [2.],\n",
      "         [2.],\n",
      "         [0.]],\n",
      "\n",
      "        [[3.],\n",
      "         [3.],\n",
      "         [3.],\n",
      "         [3.],\n",
      "         [3.],\n",
      "         [0.],\n",
      "         [0.]]])\n",
      "PackedSequence(data=tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [1.]]), batch_sizes=tensor([3, 3, 3, 3, 3, 2, 1]))\n",
      "PackedSequence(data=tensor([[-0.6259,  0.1715,  0.5444,  0.8829,  0.1278,  0.1367,  0.1361,  0.2764,\n",
      "         -0.3295, -0.4043],\n",
      "        [-0.5708,  0.0593,  0.3468,  0.8746,  0.1221, -0.2615,  0.0860,  0.5150,\n",
      "         -0.2896, -0.3114],\n",
      "        [-0.3326,  0.1173,  0.3127,  0.7802,  0.1912,  0.0668,  0.0624,  0.2617,\n",
      "         -0.2021, -0.3893],\n",
      "        [-0.7401, -0.3959, -0.2347,  0.4277,  0.3690,  0.0364, -0.3237,  0.4142,\n",
      "          0.1022,  0.1116],\n",
      "        [-0.5873, -0.3418, -0.2538,  0.3298,  0.2366, -0.2434, -0.3567,  0.3904,\n",
      "          0.2310, -0.0628],\n",
      "        [-0.5774, -0.2966, -0.0559,  0.3144,  0.0840, -0.1848, -0.4945,  0.3545,\n",
      "          0.1493,  0.0476],\n",
      "        [-0.5643, -0.3283, -0.2229,  0.3209,  0.0231, -0.0336, -0.6281,  0.5592,\n",
      "          0.0549,  0.0925],\n",
      "        [-0.3657, -0.3383, -0.1688,  0.0693, -0.0019, -0.2154, -0.6592,  0.5155,\n",
      "          0.2150,  0.1106],\n",
      "        [-0.2095, -0.3019, -0.2058,  0.0529, -0.0115, -0.2916, -0.6580,  0.4991,\n",
      "          0.1797,  0.0090],\n",
      "        [-0.4013, -0.3146, -0.2275,  0.2372,  0.1174, -0.0461, -0.5339,  0.3925,\n",
      "          0.0422,  0.0228],\n",
      "        [-0.1391, -0.2726, -0.1702,  0.0900,  0.0597, -0.2123, -0.5857,  0.4492,\n",
      "          0.1365, -0.0336],\n",
      "        [ 0.0156, -0.2355, -0.1345, -0.0339, -0.0646, -0.3198, -0.6316,  0.4077,\n",
      "          0.1988, -0.0669],\n",
      "        [-0.4180, -0.3044, -0.2379,  0.2291,  0.0832, -0.0154, -0.5574,  0.4248,\n",
      "          0.0066,  0.0444],\n",
      "        [-0.1669, -0.2550, -0.1537,  0.1059,  0.0374, -0.1580, -0.5663,  0.4173,\n",
      "          0.0988, -0.0515],\n",
      "        [ 0.0614, -0.2311, -0.1288, -0.0275, -0.0072, -0.2683, -0.5854,  0.3872,\n",
      "          0.1497, -0.0985],\n",
      "        [-0.4094, -0.3077, -0.2293,  0.2391,  0.0734, -0.0298, -0.5535,  0.4015,\n",
      "          0.0131,  0.0122],\n",
      "        [-0.2076, -0.2634, -0.1497,  0.1246,  0.0358, -0.1470, -0.5662,  0.3997,\n",
      "          0.0836, -0.0426],\n",
      "        [-0.4190, -0.3183, -0.2414,  0.2256,  0.0880, -0.0241, -0.5532,  0.4029,\n",
      "          0.0115,  0.0256]], grad_fn=<CatBackward>), batch_sizes=tensor([3, 3, 3, 3, 3, 2, 1]))\n"
     ]
    }
   ],
   "source": [
    "#完整\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as data\n",
    "\n",
    "\n",
    "train_x = [torch.Tensor([[1], [1], [1], [1], [1], [1], [1]]),\n",
    "           torch.Tensor([[2], [2], [2], [2], [2], [2]]),\n",
    "           torch.Tensor([[3], [3], [3], [3], [3]]),\n",
    "           torch.Tensor([[4], [4], [4], [4]]),\n",
    "           torch.Tensor([[5], [5], [5]]),\n",
    "           torch.Tensor([[6], [6]]),\n",
    "           torch.Tensor([[7]])\n",
    "           ]\n",
    "\n",
    "class MyData(data.Dataset):\n",
    "    def __init__(self, data_seq):\n",
    "        self.data_seq = data_seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_seq[idx]\n",
    "\n",
    "\n",
    "def collate_fn(data):\n",
    "    data.sort(key=lambda x: len(x), reverse=True)\n",
    "    data_length = [len(sq) for sq in data]\n",
    "    data = rnn_utils.pad_sequence(data, batch_first=True, padding_value=0)\n",
    "    return data, data_length\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    data = MyData(train_x)\n",
    "    data_loader = DataLoader(data, batch_size=3, shuffle=True,\n",
    "                             collate_fn=collate_fn)\n",
    "    batch_x, batch_x_len = iter(data_loader).next()\n",
    "    batch_x_pack = rnn_utils.pack_padded_sequence(batch_x,\n",
    "                                                  batch_x_len, batch_first=True)\n",
    "    print(batch_x)\n",
    "    print(batch_x_pack)\n",
    "    net = nn.RNN(1, 10, 2, batch_first=True)\n",
    "    h0 = torch.rand(2, 3, 10)\n",
    "    #c0 = torch.rand(2, 3, 10)\n",
    "    out, h1 = net(batch_x_pack, h0)\n",
    "    out_pad, out_len = rnn_utils.pad_packed_sequence(out, batch_first=True)\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
