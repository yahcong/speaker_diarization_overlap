{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1., 1.],\n",
      "        [2., 2., 2., 2., 2., 2., 0.],\n",
      "        [3., 3., 3., 3., 3., 0., 0.],\n",
      "        [4., 4., 4., 4., 0., 0., 0.],\n",
      "        [5., 5., 5., 0., 0., 0., 0.],\n",
      "        [6., 6., 0., 0., 0., 0., 0.],\n",
      "        [7., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[6., 6., 0., 0., 0., 0., 0.],\n",
      "        [5., 5., 5., 0., 0., 0., 0.]])\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "#https://zhuanlan.zhihu.com/p/59772104\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as data\n",
    "\n",
    "train_x = [torch.Tensor([1, 1, 1, 1, 1, 1, 1]),\n",
    "           torch.Tensor([2, 2, 2, 2, 2, 2]),\n",
    "           torch.Tensor([3, 3, 3, 3, 3]),\n",
    "           torch.Tensor([4, 4, 4, 4]),\n",
    "           torch.Tensor([5, 5, 5]),\n",
    "           torch.Tensor([6, 6]),\n",
    "           torch.Tensor([7])\n",
    "           ]\n",
    "\n",
    "pad_x = rnn_utils.pad_sequence(train_x, batch_first=True)\n",
    "\n",
    "print(pad_x)\n",
    "class MyData(data.Dataset):\n",
    "    def __init__(self, data_seq):\n",
    "        self.data_seq = data_seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_seq[idx]\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    #data = MyData(train_x)\n",
    "    data = MyData(pad_x)\n",
    "    data_loader = DataLoader(data, batch_size=2, shuffle=True)\n",
    "    batch_x = iter(data_loader).next()\n",
    "    print(batch_x)\n",
    "    print('END')\n",
    "    #以数据的最大长度，后两位都是00，在lstm中浪费两次计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.6631, -0.1358,  0.4446,  1.3461,  0.2082, -0.7027, -0.6471],\n",
      "        [ 2.8690, -0.4374,  0.2876,  3.1230,  0.4198, -0.0236, -1.4215]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "Linear=nn.Linear(7,7)#input_dim,out_dim\n",
    "print(Linear(pad_x[2:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 4., 4., 4.],\n",
      "        [6., 6., 0., 0.]])\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "#pad\n",
    "def collate_fn(data):\n",
    "    data.sort(key=lambda x: len(x), reverse=True)\n",
    "    data = rnn_utils.pad_sequence(data, batch_first=True, padding_value=0)\n",
    "    return data\n",
    "\n",
    "if __name__=='__main__':\n",
    "    data = MyData(train_x)\n",
    "    data_loader = DataLoader(data, batch_size=2, shuffle=True, \n",
    "                             collate_fn=collate_fn)\n",
    "    batch_x = iter(data_loader).next()\n",
    "    print(batch_x)\n",
    "    print('END')\n",
    "    #以batch的最大长度为准，而不是整个数据的最大长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2., 2., 2., 2.],\n",
      "        [4., 4., 4., 4., 0., 0.],\n",
      "        [5., 5., 5., 0., 0., 0.]]) [6, 4, 3]\n",
      "PackedSequence(data=tensor([2., 4., 5., 2., 4., 5., 2., 4., 5., 2., 4., 2., 2.]), batch_sizes=tensor([3, 3, 3, 2, 1, 1]))\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(data):\n",
    "    data.sort(key=lambda x: len(x), reverse=True)\n",
    "    data_length = [len(sq) for sq in data]\n",
    "    data = rnn_utils.pad_sequence(data, batch_first=True, padding_value=0)\n",
    "    return data, data_length\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    data = MyData(train_x)\n",
    "    data_loader = DataLoader(data, batch_size=3, shuffle=True, \n",
    "                             collate_fn=collate_fn)\n",
    "    batch_x, batch_x_len = iter(data_loader).next()\n",
    "    batch_x_pack = rnn_utils.pack_padded_sequence(batch_x, \n",
    "                                                  batch_x_len, batch_first=True)\n",
    "print(batch_x,batch_x_len)\n",
    "print(batch_x_pack)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8202,  0.9555, -1.8077, -0.6296,  2.7744,  0.6284],\n",
      "        [ 0.3939,  1.6663, -1.6440, -0.2789,  3.8227,  1.0817],\n",
      "        [-0.4596,  0.9900, -1.3149, -1.2184,  3.2859,  2.0111]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "Linear=nn.Linear(6,6)#input_dim,out_dim\n",
    "print(Linear(batch_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [2.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [2.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [2.],\n",
      "        [4.],\n",
      "        [2.],\n",
      "        [2.]])\n",
      "tensor([[2.5511],\n",
      "        [4.3836],\n",
      "        [5.2998],\n",
      "        [2.5511],\n",
      "        [4.3836],\n",
      "        [5.2998],\n",
      "        [2.5511],\n",
      "        [4.3836],\n",
      "        [5.2998],\n",
      "        [2.5511],\n",
      "        [4.3836],\n",
      "        [2.5511],\n",
      "        [2.5511]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "x=batch_x_pack.data.reshape(-1,1)#the size -1 is inferred from other dimensions\n",
    "print(x)\n",
    "Linear=nn.Linear(1,1)#(input_dim,out_dim)\n",
    "print(Linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[3.],\n",
      "         [3.],\n",
      "         [3.],\n",
      "         [3.],\n",
      "         [3.]],\n",
      "\n",
      "        [[6.],\n",
      "         [6.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[7.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]]) [5, 2, 1]\n",
      "PackedSequence(data=tensor([[3.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [3.],\n",
      "        [6.],\n",
      "        [3.],\n",
      "        [3.],\n",
      "        [3.]]), batch_sizes=tensor([3, 2, 1, 1, 1]))\n"
     ]
    }
   ],
   "source": [
    "#使其返回的数据符合 [batch, sequence_len, input_size],即batch_first\n",
    "def collate_fn(data):\n",
    "    data.sort(key=lambda x: len(x), reverse=True)\n",
    "    data_length = [len(sq) for sq in data]\n",
    "    data = rnn_utils.pad_sequence(data, batch_first=True, padding_value=0)\n",
    "    return data.unsqueeze(-1), data_length\n",
    "\n",
    "if __name__=='__main__':\n",
    "    data = MyData(train_x)\n",
    "    data_loader = DataLoader(data, batch_size=3, shuffle=True, \n",
    "                             collate_fn=collate_fn)\n",
    "    batch_x, batch_x_len = iter(data_loader).next()\n",
    "    batch_x_pack = rnn_utils.pack_padded_sequence(batch_x, \n",
    "                                                  batch_x_len, batch_first=True)\n",
    "    \n",
    "print(batch_x,batch_x_len)\n",
    "print(batch_x_pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedSequence(data=tensor([[2.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [2.],\n",
      "        [6.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [2.]]), batch_sizes=tensor([3, 2, 1, 1, 1, 1]))\n",
      "torch.Size([9, 10])\n",
      "torch.Size([9, 1])\n",
      "tensor([3, 2, 1, 1, 1, 1])\n",
      "tensor([3, 2, 1, 1, 1, 1])\n",
      "PackedSequence(data=tensor([[-0.7220, -0.4395, -0.4604, -0.0896,  0.4151,  0.2507,  0.3952, -0.4562,\n",
      "          0.1178, -0.2781],\n",
      "        [-0.8316, -0.6554, -0.5307,  0.1159,  0.7410,  0.4759,  0.6168, -0.8307,\n",
      "          0.0897, -0.4659],\n",
      "        [-0.8032, -0.7134, -0.3445,  0.1038,  0.7269,  0.4488,  0.8143, -0.9084,\n",
      "          0.1758, -0.4301],\n",
      "        [-0.0782,  0.3156, -0.4263,  0.1117, -0.0807,  0.2368,  0.0160,  0.0583,\n",
      "          0.1945,  0.1365],\n",
      "        [-0.0237, -0.0461, -0.6207,  0.0447,  0.0545,  0.4614,  0.0634, -0.5351,\n",
      "          0.2593, -0.1730],\n",
      "        [-0.2774,  0.0767, -0.4326,  0.1480,  0.1423,  0.3460,  0.3616, -0.1442,\n",
      "          0.3477,  0.0010],\n",
      "        [-0.2503,  0.1254, -0.4386,  0.0400,  0.1149,  0.2467,  0.1770, -0.1515,\n",
      "          0.2867,  0.0190],\n",
      "        [-0.1717,  0.1420, -0.4487,  0.0797,  0.1070,  0.2801,  0.2493, -0.1433,\n",
      "          0.3090,  0.0549],\n",
      "        [-0.2057,  0.1136, -0.4339,  0.0462,  0.1121,  0.2546,  0.2668, -0.1527,\n",
      "          0.3037,  0.0370]], grad_fn=<CatBackward>), batch_sizes=tensor([3, 2, 1, 1, 1, 1]))\n",
      "torch.Size([2, 3, 10])\n",
      "torch.Size([3, 6, 10])\n",
      "tensor([6, 2, 1])\n",
      "tensor([[-0.8316, -0.6554, -0.5307,  0.1159,  0.7410,  0.4759,  0.6168, -0.8307,\n",
      "          0.0897, -0.4659],\n",
      "        [-0.0237, -0.0461, -0.6207,  0.0447,  0.0545,  0.4614,  0.0634, -0.5351,\n",
      "          0.2593, -0.1730],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000]], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    data = MyData(train_x)\n",
    "    data_loader = DataLoader(data, batch_size=3, shuffle=True,\n",
    "                             collate_fn=collate_fn)\n",
    "    batch_x, batch_x_len = iter(data_loader).next()\n",
    "    batch_x_pack = rnn_utils.pack_padded_sequence(batch_x, batch_x_len, batch_first=True)\n",
    "\n",
    "    net = nn.RNN(1, 10, 2,batch_first=True)\n",
    "\n",
    "    print(batch_x_pack)\n",
    "    h0 = torch.rand(2, 3, 10)\n",
    "    out, (h1) = net(batch_x_pack,h0)\n",
    "    print(out.data.shape)#第一位表示统计整个数据中共有多少个个非零的数据。即每个数据的RNN的输出。\n",
    "    print(batch_x_pack.data.shape)\n",
    "    print(out.batch_sizes)\n",
    "    print(batch_x_pack.batch_sizes)\n",
    "    print(out)\n",
    "    print(h1.shape)#与h0的shape相同。\n",
    "    out_pad, out_len = rnn_utils.pad_packed_sequence(out, batch_first=True)\n",
    "    print(out_pad.shape)#第一位是句子数，第二位是时间步长（最长的句长），第三维是特征向量维度。\n",
    "    print(out_len)#每一个句子的长度\n",
    "    print(out_pad[1])#假如下标为1的句子真实长度为2，其余位（假如长度位3），共5位，那么out_pad[1]只有前两行有值，其余行为0（3行），\n",
    "    #表示每一个特征映射为hidden_size，其余pad0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[4.],\n",
      "         [4.],\n",
      "         [4.],\n",
      "         [4.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[5.],\n",
      "         [5.],\n",
      "         [5.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]])\n",
      "PackedSequence(data=tensor([[1.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [1.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [1.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [1.],\n",
      "        [4.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]), batch_sizes=tensor([3, 3, 3, 2, 1, 1, 1]))\n",
      "PackedSequence(data=tensor([[-0.1359,  0.1547, -0.0126,  0.3267, -0.3614,  0.4605, -0.3252,  0.4271,\n",
      "          0.0496, -0.1898],\n",
      "        [-0.2145, -0.0027, -0.0835,  0.5169, -0.3309,  0.7682, -0.4270,  0.4915,\n",
      "          0.2825, -0.3199],\n",
      "        [ 0.0034,  0.1260,  0.1975,  0.3381, -0.2281,  0.7027, -0.3199,  0.5543,\n",
      "          0.3908, -0.4691],\n",
      "        [ 0.0390,  0.0141,  0.1996,  0.3342,  0.3321,  0.7216, -0.3177,  0.4119,\n",
      "         -0.1443, -0.4634],\n",
      "        [-0.0721,  0.0880,  0.3748,  0.4482,  0.5168,  0.7089, -0.2827,  0.3850,\n",
      "         -0.2397, -0.5707],\n",
      "        [-0.0836,  0.0413,  0.3771,  0.4205,  0.2898,  0.6818, -0.3009,  0.4563,\n",
      "         -0.1500, -0.6019],\n",
      "        [ 0.2975,  0.2184,  0.1785,  0.4651,  0.3084,  0.5266, -0.2634,  0.5100,\n",
      "          0.0105, -0.6001],\n",
      "        [ 0.2640,  0.3602,  0.2391,  0.5280,  0.3299,  0.5107, -0.2126,  0.5586,\n",
      "          0.0753, -0.7156],\n",
      "        [ 0.1415,  0.3076,  0.2857,  0.5187,  0.2879,  0.5372, -0.2561,  0.5585,\n",
      "          0.0126, -0.7065],\n",
      "        [ 0.2971,  0.0669,  0.2795,  0.3965,  0.2649,  0.5070, -0.2420,  0.4636,\n",
      "         -0.0185, -0.6169],\n",
      "        [ 0.2878,  0.1170,  0.3524,  0.3967,  0.3058,  0.5367, -0.1612,  0.5114,\n",
      "         -0.0303, -0.6970],\n",
      "        [ 0.2666,  0.0950,  0.2985,  0.4163,  0.2293,  0.5084, -0.2559,  0.4933,\n",
      "         -0.0104, -0.6456],\n",
      "        [ 0.2408,  0.0647,  0.2965,  0.4273,  0.2358,  0.5152, -0.2519,  0.4892,\n",
      "         -0.0212, -0.6408],\n",
      "        [ 0.2217,  0.0856,  0.2975,  0.4380,  0.2330,  0.5047, -0.2529,  0.4923,\n",
      "         -0.0195, -0.6384]], grad_fn=<CatBackward>), batch_sizes=tensor([3, 3, 3, 2, 1, 1, 1]))\n"
     ]
    }
   ],
   "source": [
    "#完整\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as data\n",
    "\n",
    "\n",
    "train_x = [torch.Tensor([1, 1, 1, 1, 1, 1, 1]),\n",
    "           torch.Tensor([2, 2, 2, 2, 2, 2]),\n",
    "           torch.Tensor([3, 3, 3, 3, 3]),\n",
    "           torch.Tensor([4, 4, 4, 4]),\n",
    "           torch.Tensor([5, 5, 5]),\n",
    "           torch.Tensor([6, 6]),\n",
    "           torch.Tensor([7])\n",
    "           ]\n",
    "\n",
    "class MyData(data.Dataset):\n",
    "    def __init__(self, data_seq):\n",
    "        self.data_seq = data_seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_seq[idx]\n",
    "\n",
    "\n",
    "def collate_fn(data):\n",
    "    data.sort(key=lambda x: len(x), reverse=True)\n",
    "    data_length = [len(sq) for sq in data]\n",
    "    data = rnn_utils.pad_sequence(data, batch_first=True, padding_value=0)\n",
    "    return data.unsqueeze(-1), data_length\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    data = MyData(train_x)\n",
    "    data_loader = DataLoader(data, batch_size=3, shuffle=True,\n",
    "                             collate_fn=collate_fn)\n",
    "    batch_x, batch_x_len = iter(data_loader).next()\n",
    "    batch_x_pack = rnn_utils.pack_padded_sequence(batch_x,\n",
    "                                                  batch_x_len, batch_first=True)\n",
    "    print(batch_x)\n",
    "    print(batch_x_pack)\n",
    "    net = nn.RNN(1, 10, 2, batch_first=True)\n",
    "    h0 = torch.rand(2, 3, 10)\n",
    "    #c0 = torch.rand(2, 3, 10)\n",
    "    out, h1 = net(batch_x_pack, h0)\n",
    "    out_pad, out_len = rnn_utils.pad_packed_sequence(out, batch_first=True)\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
