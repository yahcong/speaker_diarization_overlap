{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]]), tensor([[2., 2.],\n",
      "        [2., 2.],\n",
      "        [2., 2.]]), tensor([[3., 3.],\n",
      "        [3., 3.]]), tensor([[4., 4.],\n",
      "        [4., 4.]]), tensor([[5., 5.]]), tensor([[6., 6.]])]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as data\n",
    "\n",
    "train_x = [torch.Tensor([[1, 1], [1, 1], [1, 1], [1,1]]),\n",
    "           torch.Tensor([[2, 2], [2, 2], [2, 2]]),\n",
    "           torch.Tensor([[3, 3], [3, 3]]),\n",
    "           torch.Tensor([[4, 4], [4, 4]]),\n",
    "           torch.Tensor([[5, 5]]),\n",
    "           torch.Tensor([[6,6]])\n",
    "        ]\n",
    "print(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2., 2.],\n",
      "         [2., 2.],\n",
      "         [2., 2.]],\n",
      "\n",
      "        [[4., 4.],\n",
      "         [4., 4.],\n",
      "         [0., 0.]]]) [3, 2]\n",
      "PackedSequence(data=tensor([[2., 2.],\n",
      "        [4., 4.],\n",
      "        [2., 2.],\n",
      "        [4., 4.],\n",
      "        [2., 2.]]), batch_sizes=tensor([2, 2, 1]))\n"
     ]
    }
   ],
   "source": [
    "class MyData(data.Dataset):\n",
    "    def __init__(self, data_seq):\n",
    "        self.data_seq = data_seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_seq[idx]\n",
    "    \n",
    "def collate_fn(data):\n",
    "    data.sort(key=lambda x: len(x), reverse=True)\n",
    "    data_length = [len(sq) for sq in data]\n",
    "    data = rnn_utils.pad_sequence(data, batch_first=True, padding_value=0)\n",
    "    return data, data_length\n",
    "\n",
    "batch_size=2\n",
    "if __name__=='__main__':\n",
    "    data = MyData(train_x)\n",
    "    data_loader = DataLoader(data, batch_size=batch_size, shuffle=True, \n",
    "                             collate_fn=collate_fn)\n",
    "    batch_x, batch_x_len = iter(data_loader).next()\n",
    "    batch_x_pack = rnn_utils.pack_padded_sequence(batch_x, \n",
    "                                                  batch_x_len, batch_first=True)\n",
    "print(batch_x,batch_x_len)\n",
    "print(batch_x_pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack(data):\n",
    "    data = MyData(data)\n",
    "    data_loader = DataLoader(data, batch_size=batch_size, shuffle=True, \n",
    "                             collate_fn=collate_fn)\n",
    "    batch_x, batch_x_len = iter(data_loader).next()\n",
    "    batch_x_pack = rnn_utils.pack_padded_sequence(batch_x, \n",
    "                                                  batch_x_len, batch_first=True)\n",
    "    return batch_x_pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.6722, -0.5852],\n",
      "         [-0.9685, -0.6535]]], grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "#RNN\n",
    "num_layers=1\n",
    "input_size=2\n",
    "output_size=2\n",
    "\n",
    "net = nn.RNN(input_size, output_size, num_layers)#输入维度2，输出维度3\n",
    "h0 = torch.rand(num_layers, batch_size, output_size)\n",
    "#print(batch_x_pack.data.shape)#\n",
    "out, (h1) = net(batch_x_pack,h0)\n",
    "#print(out.data.shape)#\n",
    "print(h1)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4714, -2.5254],\n",
      "        [-1.0795, -4.8525],\n",
      "        [-0.4714, -2.5254],\n",
      "        [-1.0795, -4.8525],\n",
      "        [-0.4714, -2.5254]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "#Linear\n",
    "Linear=nn.Linear(input_size,output_size)\n",
    "output=Linear(batch_x_pack.data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.6763, -0.9380],\n",
       "          [ 0.9015, -0.9831]]], grad_fn=<StackBackward>),\n",
       " tensor([[[ 0.6763, -0.9380],\n",
       "          [ 0.9015, -0.9831]]], grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0 = torch.rand(1, 2, 2)#batch_first=False\n",
    "net(output.data[0:2].reshape(1,2,-1),h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "tensor([[[-0.4714, -2.5254],\n",
      "         [-1.0795, -4.8525]]])\n"
     ]
    }
   ],
   "source": [
    "#X与h的shape对齐。\n",
    "h_size=h0.shape[1]\n",
    "xdata=output.data[0:2].reshape(1,2,-1)\n",
    "print(h_size)\n",
    "x_size=xdata.shape[1]\n",
    "print(x_size)\n",
    "if (h_size<x_size):\n",
    "    xdata=xdata[:,0:h_size,:]\n",
    "print(xdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n",
      "tensor([[[2., 2.],\n",
      "         [4., 4.]]])\n",
      "tensor(2)\n",
      "[tensor([[[-0.4714, -2.5254],\n",
      "         [-1.0795, -4.8525]]])]\n",
      "train_h\n",
      "[tensor([[[-0.4714, -2.5254],\n",
      "         [-1.0795, -4.8525]]])]\n",
      "tensor([[[-0.4714, -2.5254],\n",
      "         [-1.0795, -4.8525]]])\n",
      "out\n",
      "tensor([[[ 0.5030, -0.8436],\n",
      "         [ 0.7255, -0.9101]]], grad_fn=<StackBackward>)\n",
      "tensor([[[ 0.5030, -0.8436],\n",
      "         [ 0.7255, -0.9101]]], grad_fn=<StackBackward>)\n",
      "tensor(2)\n",
      "tensor([[[2., 2.]]])\n",
      "tensor(1)\n",
      "[tensor([[[-0.4714, -2.5254]]]), tensor([[[-0.4714, -2.5254]]])]\n",
      "train_h\n",
      "[tensor([[[-0.4714, -2.5254]]]), tensor([[[-0.4714, -2.5254]]])]\n",
      "tensor([[[-0.4714, -2.5254]],\n",
      "\n",
      "        [[-0.4714, -2.5254]]])\n",
      "out\n",
      "tensor([[[ 0.5030, -0.8436]],\n",
      "\n",
      "        [[ 0.7784, -0.8047]]], grad_fn=<StackBackward>)\n",
      "tensor([[[ 0.7784, -0.8047]]], grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "#for循环获取h的batch\n",
    "length=0\n",
    "xdatas=[]\n",
    "for index in range(len(batch_x_pack.batch_sizes)-1):\n",
    "    h_batch_size=batch_x_pack.batch_sizes[index]\n",
    "    print(h_batch_size)\n",
    "    if(len(xdatas)==2):\n",
    "        del xdatas[0]\n",
    "    out=output.data[length:length+h_batch_size].reshape(1,h_batch_size,-1)\n",
    "    length=length+h_batch_size\n",
    "    h_size=batch_x_pack.batch_sizes[index+1]\n",
    "    h= batch_x_pack.data[length:length+h_size].reshape(1,h_size,-1)\n",
    "    print(h)\n",
    "    \n",
    "    #size 调整\n",
    "    print(h_size)\n",
    "    xdatas.append(out[:,0:h_size,:])\n",
    "    xdatas[0]=xdatas[0][:,0:h_size,:]\n",
    "    print(xdatas)\n",
    "    \n",
    "    #pack\n",
    "    train_h=xdatas\n",
    "    print('train_h')\n",
    "    print(train_h)\n",
    "    if(len(xdatas)==2):\n",
    "        train_h=torch.stack((xdatas[0],xdatas[1]),dim=1).reshape(2,h_size,-1)\n",
    "    else:\n",
    "        train_h=xdatas[0]\n",
    "    print(train_h)\n",
    "    #Net\n",
    "    out,h1=net(train_h,h)\n",
    "    print('out')\n",
    "    print(out)\n",
    "    print(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for h_batch_size in range(len(batch_x_pack.batch_sizes)):\n",
    "    print(h_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
